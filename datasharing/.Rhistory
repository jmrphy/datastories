brexit.tweets$text = gsub(":", "", brexit.tweets$text) #not all punctuation, just colons leftover from RTs
brexit.tweets$text <- str_replace_all(brexit.tweets$text, "http\\S+\\s*", "") #urls
brexit.tweets <- subset(brexit.tweets, is_retweet==FALSE)
# preprocessing and tokenization
it_brexit.tweets <- itoken(as.character(brexit.tweets$text),
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = brexit.tweets$status_id,
progressbar = TRUE)
# creating vocabulary and document-term matrix
dtm_brexit.tweets <- create_dtm(it_brexit.tweets, vectorizer)
# transforming data with tf-idf
dtm_brexit.tweets_tfidf <- fit_transform(dtm_brexit.tweets, tfidf)
# loading classification model
glmnet_classifier <- readRDS('data/djs-classifier-glmnet.RDS')
# predict probabilities of positiveness
preds_brexit.tweets <- predict(glmnet_classifier, dtm_brexit.tweets_tfidf, type = 'response')[ ,1]
# adding rates to initial dataset
brexit.tweets$datacont <- preds_brexit.tweets
brexit.tweets$datadriven <- ifelse(brexit.tweets$datacont>.5, 1, 0)
glmnet_classifier <- readRDS("data/djs-classifier-glmnet.RDS")
# predict probabilities of positiveness
preds_brexit.tweets <- predict(glmnet_classifier, dtm_brexit.tweets_tfidf, type = 'response')[ ,1]
?predict
# predict probabilities of positiveness
preds_brexit.tweets <- predict(glmnet_classifier, dtm_brexit.tweets_tfidf)
# predict probabilities of positiveness
preds_brexit.tweets <- predict(glmnet_classifier, dtm_brexit.tweets_tfidf, type = 'response')
glmnet_classifier
dims(glmnet_classifier)
dim(glmnet_classifier)
names(glmnet_classifier)
summary(brexit.tweets$text)
names(brexit.tweets)
?create_dtm
?fit_transform
# Function for dealing with irregular symbols
conv_fun <- function(x) iconv(x, "latin1", "ASCII", "")
# Load while cleaning some irregular symbols
tweets_classified <- read_csv('data/djs-hand-coded.csv') %>%
# converting some symbols
dmap_at('text', conv_fun)
# Merge in user information scraped in djs-scrape.R
djs <-read.csv("data/djs-users.csv")
tweets_classified <- merge(tweets_classified, djs, by="user_id")
# Assign 1 to tweets coded 'y' and 0 to tweets not coded as 'y'
tweets_classified$data <- recode(tweets_classified$data, y = 1)
tweets_classified$data[is.na(tweets_classified$data)] <- 0
# Write combo of tweets and user info to a .csv for later
# write.csv(tweets_classified, file="data/djs-coded-with-users.csv")
# Othe processing: removes ampersands, RT and/or via, @, :, and URLs
tweets_classified$text = gsub("&amp", "", tweets_classified$text)
tweets_classified$text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", tweets_classified$text)
tweets_classified$text = gsub("@\\w+", "", tweets_classified$text)
tweets_classified$text = gsub(":", "", tweets_classified$text) #not all punctuation, just colons leftover from RTs
tweets_classified$text <- str_replace_all(tweets_classified$text, "http\\S+\\s*", "") #urls
tweets_classified <- subset(tweets_classified, lang=="en")
# Convert numeric status id to character
tweets_classified$status_id <- as.character(tweets_classified$status_id)
# there are some tweets with NA ids that we replace with dummies
# tweets_classified_na <- tweets_classified %>%
#   filter(is.na(status_id) == TRUE) %>%
#   mutate(id = c(1:n()))
# tweets_classified <- tweets_classified %>%
#   filter(!is.na(id)) %>%
#   rbind(., tweets_classified_na)
# Split data into train and test
set.seed(2340)
trainIndex <- createDataPartition(tweets_classified$data, p = 0.7,
list = FALSE,
times = 1)
tweets_train <- tweets_classified[trainIndex, ]
tweets_test <- tweets_classified[-trainIndex, ]
#### Vectorization
# define preprocessing function and tokenization function
prep_fun <- tolower
tok_fun <- word_tokenizer
it_train <- itoken(tweets_train$text,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = tweets_train$status_id,
progressbar = TRUE)
it_test <- itoken(tweets_test$text,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = tweets_test$status_id,
progressbar = TRUE)
# creating vocabulary and document-term matrix
vocab <- create_vocabulary(it_train)
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dtm_test <- create_dtm(it_test, vectorizer)
# define tf-idf model
tfidf <- TfIdf$new()
# fit the model to the train data and transform it with the fitted model
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
dtm_test_tfidf <- fit_transform(dtm_test, tfidf)
# train the model
t1 <- Sys.time()
glmnet_classifier <- cv.glmnet(x = dtm_train_tfidf,
y = tweets_train[['data']],
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = 7)
print(difftime(Sys.time(), t1, units = 'mins'))
plot(glmnet_classifier)
# print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
preds <- predict(glmnet_classifier, dtm_test_tfidf, type = 'response')[ ,1]
# auc(as.numeric(tweets_test$data), preds)
############### save the model for future using
saveRDS(glmnet_classifier, 'data/djs-classifier-glmnet.RDS')
#######################################################
glmnet_classifier <- readRDS("data/djs-classifier-glmnet.RDS")
brexit.tweets <- read.csv("data/brexit-tweets-and-users.csv")
brexit.tweets$text<-conv_fun(brexit.tweets$text)
brexit.tweets <- subset(brexit.tweets, lang=="en")
brexit.tweets$text = gsub("&amp", "", brexit.tweets$text)
brexit.tweets$text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", brexit.tweets$text)
brexit.tweets$text = gsub("@\\w+", "", brexit.tweets$text)
brexit.tweets$text = gsub(":", "", brexit.tweets$text) #not all punctuation, just colons leftover from RTs
brexit.tweets$text <- str_replace_all(brexit.tweets$text, "http\\S+\\s*", "") #urls
brexit.tweets <- subset(brexit.tweets, is_retweet==FALSE)
# preprocessing and tokenization
it_brexit.tweets <- itoken(as.character(brexit.tweets$text),
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = brexit.tweets$status_id,
progressbar = TRUE)
# creating vocabulary and document-term matrix
dtm_brexit.tweets <- create_dtm(it_brexit.tweets, vectorizer)
# transforming data with tf-idf
dtm_brexit.tweets_tfidf <- fit_transform(dtm_brexit.tweets, tfidf)
# predict probabilities of positiveness
preds_brexit.tweets <- predict(glmnet_classifier, dtm_brexit.tweets_tfidf, type = 'response')[ ,1]
# adding rates to initial dataset
brexit.tweets$datacont <- preds_brexit.tweets
brexit.tweets$datadriven <- ifelse(brexit.tweets$datacont>.5, 1, 0)
examples<-subset(brexit.tweets, datacont>.75)
head(examples[c("text")], 10)
examples<-subset(brexit.tweets, datacont>.9)
head(examples[c("text")], 10)
examples<-subset(brexit.tweets, datacont>.8)
head(examples[c("text")], 10)
brexit.tweets$media_type <- recode(as.character(brexit.tweets$media_type), photo = "Photo", .missing = "No Photo")
brexit.tweets$links <- ifelse(is.na(brexit.tweets$urls_url), 0, 1)
brexit.tweets$reply <- ifelse(is.na(brexit.tweets$reply_to_screen_name), 0, 1)
write.csv(brexit.tweets, "data/brexit-classified.csv")
df <- read.csv("data/brexit-classified.csv")
df <- subset(df, is_retweet==FALSE & reply==0)
mod<-zelig(retweet_count ~ followers_count + datacont, data=df, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + datadriven, data=df, model='ls', cite=F)
summary(mod)
mod<-zelig(log(retweet_count+1) ~ followers_count + datadriven, data=df, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + datadriven, data=df, model='negbin', cite=F)
summary(mod)
brexit.tweets$datadriven <- ifelse(brexit.tweets$datacont>.8, 1, 0)
write.csv(brexit.tweets, "data/brexit-classified.csv")
df <- read.csv("data/brexit-classified.csv")
df <- subset(df, is_retweet==FALSE & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + datadriven, data=df, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + datadriven, data=df, model='ls', cite=F)
summary(mod)
brexit.tweets$datadriven <- ifelse(brexit.tweets$datacont>.6, 1, 0)
write.csv(brexit.tweets, "data/brexit-classified.csv")
df <- read.csv("data/brexit-classified.csv")
df <- subset(df, is_retweet==FALSE & reply==0)
mod<-zelig(retweet_count ~ followers_count + datadriven, data=df, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + datacont, data=df, model='ls', cite=F)
summary(mod)
###### Search for tweets mentioning Trump and Russia
trump<-search_tweets(q = 'Russia Trump', include_rts=F, n = 50000, retryonratelimit = T)
##### Extract user information from tweets
trumpusers<-users_data(trump)
##### Assign 0 for these tweets not necessarily mentioning data
trump$data <- 0
##### Conduct multiple searches mentioning Trump-Russia and different phrases indicating data references
trumpdata<-Map("search_tweets",
c('Trump Russia AND "graph shows" OR "graph reveals" OR "graph indicates" OR "graph suggests" OR "graph proves"',
'Trump Russia AND "chart shows" OR "chart reveals" OR "chart indicates" OR "chart suggests" OR "chart proves"',
'Trump Russia AND "map shows" OR "map reveals" OR "map indicates" OR "map suggests" OR "map proves"',
'Trump Russia AND "poll shows" OR "poll reveals" OR "poll indicates" OR "poll suggests" OR "poll proves"',
'Trump Russia AND "polling shows" OR "polling reveals" OR "polling indicates" OR "polling suggests" OR "polling proves"',
'Trump Russia AND "studies show" OR "studies reveal" OR "studies indicate" OR "studies suggest" OR "studies prove"',
'Trump Russia AND "study shows" OR "study reveals" OR "study indicates" OR "study suggests" OR "study proves"',
'Trump Russia AND "data shows" OR "data reveals" OR "data indicates" OR "data suggests" OR "data proves"',
'Trump Russia AND "data show" OR "data reveal" OR "data indicate" OR "data suggest" OR "data prove"',
'Trump Russia AND "figure shows" OR "figure reveals" OR "figure indicates" OR "figure suggests" OR "figure proves"'),
include_rts=F, n = 100000, retryonratelimit = T)
# Unlist into dataframe preserving rtweet's attributes
trumpdata<-do_call_rbind(trumpdata)
trumpe<-sample(trump, 1000)
trumpe<-sample(trump, 1000, replace=T)
rm(trump)
?sample
trumpe<-sample_n(trump, 10000)
names(trumpe)
trumpz<-sample_n(trumpe[1:42], 10000)
###### Search for tweets mentioning Trump and Russia
trump<-search_tweets(q = 'Russia Trump', include_rts=F, n = 10000, retryonratelimit = T)
##### Extract user information from tweets
trumpusers<-users_data(trump)
##### Assign 0 for these tweets not necessarily mentioning data
trump$data <- 0
rm(trumpe)
# Remove duplicates
trumpie<-trumpdata %>% distinct(status_id, .keep_all = TRUE)
trumpie
# Extract user information for each user
trumpdatausers<-users_data(trumpdata)
# Assign 1 for these tweets mentioning data
trumpdata$data <- 1
trump[!(trump$status_id %in% trumpdata$status_id),]
# Remove from non-data set any tweets found in set mentioning data
trump <- trump[!(trump$status_id %in% trumpdata$status_id),]
# Bind both groups of users into one dataframe
trumpusers<-rbind(trumpusers, trumpdatausers)
# Bind both sets of tweets into one dataframe
trump<-rbind(trump, trumpdata)
merge(unique(trump), unique(trumpusers), by="user_id")
# Merge user info with tweet info
trump.df<-merge(unique(trump), unique(trumpusers), by="user_id")
trump.df <- trump.df %>% distinct(status_id, .keep_all = TRUE)
trump.df$media_type <- recode(as.character(trump.df$media_type), photo = "Photo", .missing = "No Photo")
trump.df$links <- ifelse(is.na(trump.df$urls_url), 0, 1)
trump.df$reply <- ifelse(is.na(trump.df$reply_to_screen_name), 0, 1)
write.csv("data/trump-tweets-and-users.csv")
write.csv(trump.df, "data/trump-tweets-and-users.csv")
trump.df[14:64] <- sapply(trump.df[14:64], function(x) unlist(x))
write.csv(trump.df, "data/trump-tweets-and-users.csv")
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=subset(trump.df, is_retweet==F & reply==0), model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=subset(trump.df, retweet_count<3000,  is_retweet==F & reply==0), model='ls', cite=F)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=subset(trump.df, retweet_count<3000 &  is_retweet==F & reply==0), model='ls', cite=F)
summary(mod)
qplot(trump.df$data, trump.df$retweet_count)
qplot(as.factor(trump.df$data), log(trump.df$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(trump.df$data, retweet_count<3000 &  is_retweet==F & reply==0)
sub<-subset(trump.df, retweet_count<3000 &  is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(trump.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(trump.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<4000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
sub<-subset(trump.df, retweet_count<6000 & is_retweet==F & reply==0)
sub<-subset(trump.df, retweet_count<4000 & is_retweet==F & reply==0)
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count+1 ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
trumpdata$text
climate<-Map("search_tweets",
c("climate change",
"global warming",
include_rts=F, n = 10000, retryonratelimit = T)
climate<-Map("search_tweets",
c("climate change",
"global warming"),
include_rts=F, n = 10000, retryonratelimit = T)
climate<-do_call_rbind(climate)
climateusers<-users_data(climate)
climate$data <- 0
climatedata1<-Map("search_tweets",
c('global warming AND "graph shows" OR "graph reveals" OR "graph indicates" OR "graph suggests" OR "graph proves"',
'global warming AND "chart shows" OR "chart reveals" OR "chart indicates" OR "chart suggests" OR "chart proves"',
'global warming AND "map shows" OR "map reveals" OR "map indicates" OR "map suggests" OR "map proves"',
'global warming AND "poll shows" OR "poll reveals" OR "poll indicates" OR "poll suggests" OR "poll proves"',
'global warming AND "polling shows" OR "polling reveals" OR "polling indicates" OR "polling suggests" OR "polling proves"',
'global warming AND "studies show" OR "studies reveal" OR "studies indicate" OR "studies suggest" OR "studies prove"',
'global warming AND "study shows" OR "study reveals" OR "study indicates" OR "study suggests" OR "study proves"',
'global warming AND "data shows" OR "data reveals" OR "data indicates" OR "data suggests" OR "data proves"',
'global warming AND "data show" OR "data reveal" OR "data indicate" OR "data suggest" OR "data prove"',
'global warming AND "figure shows" OR "figure reveals" OR "figure indicates" OR "figure suggests" OR "figure proves"'),
include_rts=F, n = 100000, retryonratelimit = T)
climatedata<-Map("search_tweets",
c('global warming AND "graph shows" OR "graph reveals" OR "graph indicates" OR "graph suggests" OR "graph proves"',
'global warming AND "chart shows" OR "chart reveals" OR "chart indicates" OR "chart suggests" OR "chart proves"',
'global warming AND "map shows" OR "map reveals" OR "map indicates" OR "map suggests" OR "map proves"',
'global warming AND "poll shows" OR "poll reveals" OR "poll indicates" OR "poll suggests" OR "poll proves"',
'global warming AND "polling shows" OR "polling reveals" OR "polling indicates" OR "polling suggests" OR "polling proves"',
'global warming AND "studies show" OR "studies reveal" OR "studies indicate" OR "studies suggest" OR "studies prove"',
'global warming AND "study shows" OR "study reveals" OR "study indicates" OR "study suggests" OR "study proves"',
'global warming AND "data shows" OR "data reveals" OR "data indicates" OR "data suggests" OR "data proves"',
'global warming AND "data show" OR "data reveal" OR "data indicate" OR "data suggest" OR "data prove"',
'global warming AND "figure shows" OR "figure reveals" OR "figure indicates" OR "figure suggests" OR "figure proves"',
'climate change AND "graph shows" OR "graph reveals" OR "graph indicates" OR "graph suggests" OR "graph proves"',
'climate change AND "chart shows" OR "chart reveals" OR "chart indicates" OR "chart suggests" OR "chart proves"',
'climate change AND "map shows" OR "map reveals" OR "map indicates" OR "map suggests" OR "map proves"',
'climate change AND "poll shows" OR "poll reveals" OR "poll indicates" OR "poll suggests" OR "poll proves"',
'climate change AND "polling shows" OR "polling reveals" OR "polling indicates" OR "polling suggests" OR "polling proves"',
'climate change AND "studies show" OR "studies reveal" OR "studies indicate" OR "studies suggest" OR "studies prove"',
'climate change AND "study shows" OR "study reveals" OR "study indicates" OR "study suggests" OR "study proves"',
'climate change AND "data shows" OR "data reveals" OR "data indicates" OR "data suggests" OR "data proves"',
'climate change AND "data show" OR "data reveal" OR "data indicate" OR "data suggest" OR "data prove"',
'climate change AND "figure shows" OR "figure reveals" OR "figure indicates" OR "figure suggests" OR "figure proves"'),
include_rts=F, n = 100000, retryonratelimit = T)
distinct(climateusers$status_id, .keep_all = TRUE)
names(climateusers)
climateusers <- distinct(climateusers$user_id, .keep_all = TRUE)
climateusers$user_id
climateusers %>% distinct(status_id, .keep_all = TRUE)
climateusers <- climateusers %>% distinct(status_id, .keep_all = TRUE)
climateusers %>% distinct(user_id, .keep_all = TRUE)
climateusers <- climateusers %>% distinct(user_id, .keep_all = TRUE)
climate$data <- 0
climatedata <- do_call_rbind(climatedata)
climateusersdata <- users_data(climatedata)
climatedata$data <- 1
climate <- climate[!(climate$status_id %in% climatedata$status_id),]
climateusers<-rbind(climateusers, climatedatausers)
climatedatausers <- users_data(climatedata)
climateusers<-rbind(climateusers, climatedatausers)
climate<-rbind(climate, climatedata)
climate.df<-merge(unique(climate), unique(climateusers), by="user_id")
climate.df %>% distinct(status_id, .keep_all = TRUE)
climate.df<- climate.df %>% distinct(status_id, .keep_all = TRUE)
climate.df$media_type <- recode(as.character(climate.df$media_type), photo = "Photo", .missing = "No Photo")
climate.df$links <- ifelse(is.na(climate.df$urls_url), 0, 1)
names(climate.df)
climate.df$reply <- ifelse(is.na(climate.df$reply_to_screen_name), 0, 1)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=subset(climate.df, is_retweet==FALSE & reply==0), model='ls', cite=F)
summary(mod)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=subset(climate.df, is_retweet==FALSE & reply==0), model='ls', cite=F)
summary(mod)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=subset(climate.df, is_retweet==FALSE & reply==0), model='negbinom', cite=F)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=subset(climate.df, is_retweet==FALSE & reply==0), model='negbin', cite=F)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=subset(climate.df, is_retweet==FALSE & reply==0), model='negbin', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
write.csv(climate.df, "climate_tweets_and_users.csv")
climate.df[14:61] <- sapply(climate.df[14:61], function(x) unlist(x))
write.csv(climate.df, "climate_tweets_and_users.csv")
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
climate.df<-read.csv(climate.df, "data/climate-tweets-and-users.csv")
climate.df<-read.csv(climate.df, "data/climate-tweets-and-users.csv")
sub<-subset(climate.df, is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(climate.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
trump.df<-read.csv(trump.df, "data/trump-tweets-and-users.csv")
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
trump.df<-read.csv("data/trump-tweets-and-users.csv")
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<4000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<4000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<500 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<300 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<200 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<100 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + link + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
names(sub)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<5000 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<500 & is_retweet==F & reply==0)
mod<-zelig(log(retweet_count+1) ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + links + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
climate.df<-read.csv("data/climate-tweets-and-users.csv")
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
climate.df<-read.csv("data/climate-tweets-and-users.csv")
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(climate.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(climate.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
sub<-subset(climate.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(climate.df, retweet_count<2000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
sub<-subset(climate.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="boxplot")
trump.df<-read.csv("data/trump-tweets-and-users.csv")
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
climate.df<-read.csv("data/climate-tweets-and-users.csv")
sub<-subset(climate.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), sub$retweet_count,  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
climate.df<-read.csv("data/climate-tweets-and-users.csv")
sub<-subset(climate.df, retweet_count<1000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
trump.df<-read.csv("data/trump-tweets-and-users.csv")
sub<-subset(trump.df, retweet_count<3000 & is_retweet==F & reply==0)
mod<-zelig(retweet_count ~ followers_count + as.factor(data), data=sub, model='ls', cite=F)
summary(mod)
qplot(as.factor(sub$data), log(sub$retweet_count+1),  ylab = "Number of Retweets (Log)", xlab="Data-driven?", geom="violin")
setwd("/Volumes/justin_hd/gh_projects/datastories/datasharing")
# You'll need to change this line
# Set working directory to wherever /datasharing/ is
setwd("/Volumes/justin_hd/gh_projects/datastories/datasharing/")
